<html>
<style>
body{
  font-family: Verdana;
  text-indent: 50px;
}
</style>
<body style="background-color:rgb(252, 204, 140)";>
<h1 style="color:rgb(115, 72, 51)"> <center>ETHICAL REFLECTION 1</center> </h1>
  <p style="color:280003";>
      Safety. A concept that is desired by most but only possessed by some. Without safety, the world feels like a more dangerous and scary place. With it, you feel protected from any possible threats. Both those who have safety and those who want it, usually seek it from family, friends, and above all, the government. Overall, the government does a really good job with keeping everyone safe through things such as arresting killers and sketchy people. However, they also use methods that are risky and could actually put more people in danger rather than helping them.
  </p>
  <p style="color:280003";>
      As a way to ensure future safety and security, the government has put "Risk Assessments" (also known as Northpointe and COMPAS)  into effect. "Machine Bias", an article posted on ProRepublica by Julia Angwin, Jeff Larson and Lauren Kirchner, explains how these risk assessments scan the face of the criminal and use the details of their crime to sort of decide whether or not they could pose as a future threat to the community. This seems ideal because it will put people behind bars who deserve it and keep people who simply messed up on the proper punishment as well. However, the system includes many flaws. The facial recognition is racially biased in the sense that they give people of color the harsher punishments even if their crime was small and, in some cases, harmless. Similarly, they give white people and white passing people the benefit of the doubt and assume they won't be harmful in the future. This is problematic because not only are innocent people going to jail and taking up unnecessary space but the people who should be there are walking the streets and stripping people of the safety they thought they had.
</p>
<p>
    Additionally, to make things even more suspicious, the government keeps secrets about the system. In "Code of Silence", an article posted on Washington Monthly by Rebecca Wexler, it says how a man was demoted by the system for "being male" but it was ignored because Northpointe "refuses to reveal how it weighs". If it wasn't odd enough that we are relying on a machine to determine who gets put in jail and for how long, it is even more eerie that the public can't even know details about something that's supposed to keep them safe. Along with a gender bias, there is a very heavy race bias. Critics of the system agree that it "disproportionately harm(s) minorities and entrench(es) existing inequalities in criminal justice". By singling out a certain race as dangerous, the government is reinforcing ideas of racism and making it seem as if being white is better and more acceptable then being another race. Perhaps removing the gender and race tests will make the system more effective and allow for a fair playing field.
</p>
<p style="color:280003";>
    In conclusion, the systems in place that determine the fate of criminals is ineffective and flawed. It uses factors of the criminal's identity that should perhaps not even be considered when deciding whether or not a criminal will be hazardous in the future. Without these immediate red lights that go off when someone is identified as male or not white, the criminal justice system will adequately make the world a much safer place.
</p>
</body>
</html>
